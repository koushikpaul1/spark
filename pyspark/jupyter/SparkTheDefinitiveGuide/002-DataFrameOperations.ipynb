{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession created with name as 'spark'\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")\n",
    "print(\"SparkSession created with name as 'spark'\")\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('../../data/jose_portilla/Spark_DataFrames/appl_stock.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "|      Date|      Open|      High|               Low|     Close|   Volume|         Adj Close|\n",
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|214.379993|150476200|27.774976000000002|\n",
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Close<500\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      open|     close|\n",
      "+----------+----------+\n",
      "|213.429998|214.009998|\n",
      "|214.599998|214.379993|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Close<500').select('open','close').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      open|     close|\n",
      "+----------+----------+\n",
      "|213.429998|214.009998|\n",
      "|214.599998|214.379993|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['close']<500).select(['open','close']).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+----------+------------------+---------+------------------+\n",
      "|      Date|      Open|              High|       Low|             Close|   Volume|         Adj Close|\n",
      "+----------+----------+------------------+----------+------------------+---------+------------------+\n",
      "|2010-02-12|198.109995|        201.639996|195.500002|200.37999299999998|163867200|25.961142000000002|\n",
      "|2010-02-24|198.229998|201.44000400000002|197.840002|            200.66|115141600|         25.997419|\n",
      "+----------+----------+------------------+----------+------------------+---------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Open'] <200) & (df['close'] > 200)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "|      Date|      Open|      High|               Low|     Close|   Volume|         Adj Close|\n",
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|214.379993|150476200|27.774976000000002|\n",
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, col, column\n",
    "df.filter((col('Close')<500) & (col('Close')>200) ).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2013-08-14', Open=497.88002, High=504.249992, Low=493.40002400000003, Close=498.500008, Volume=189093100, Adj Close=66.408129),\n",
       " Row(Date='2013-09-04', Open=499.560005, High=502.240013, Low=496.279984, Close=498.690025, Volume=86258200, Adj Close=66.43344300000001),\n",
       " Row(Date='2013-09-06', Open=498.43998, High=499.379974, Low=489.950012, Close=498.22000099999997, Volume=89881400, Adj Close=66.370828),\n",
       " Row(Date='2013-10-15', Open=497.510025, High=502.000008, Low=495.52002000000005, Close=498.679985, Volume=80018400, Adj Close=66.432105),\n",
       " Row(Date='2014-01-30', Open=502.539993, High=506.49997699999994, Low=496.70002, Close=499.779984, Volume=169625400, Adj Close=66.967353)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=df.filter((col('Close')<500) & (col('Close')>498) ).collect()\n",
    "result # List of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date='2013-08-14', Open=497.88002, High=504.249992, Low=493.40002400000003, Close=498.500008, Volume=189093100, Adj Close=66.408129)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row=result[0] # Row\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189093100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.asDict()['Volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=spark.read.csv('../../data/jose_portilla/Spark_DataFrames/sales_info.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "+-------+-------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   GOOG|            220.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "|     FB|            610.0|\n",
      "|   APPL|            370.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('company').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|     660.0|\n",
      "|   MSFT|     967.0|\n",
      "|     FB|    1220.0|\n",
      "|   APPL|    1480.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('company').sum().show() # only sum is numeric thats why only sales is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+------------------+-----------+------------------+\n",
      "|      Date| sum(Open)| sum(High)|          sum(Low)|        sum(Close)|sum(Volume)|    sum(Adj Close)|\n",
      "+----------+----------+----------+------------------+------------------+-----------+------------------+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|        214.009998|  123432400|         27.727039|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|        214.379993|  150476200|27.774976000000002|\n",
      "|2010-01-06|214.379993|    215.23|        210.750004|        210.969995|  138040000|27.333178000000004|\n",
      "|2010-01-07|    211.75|212.000006|        209.050005|            210.58|  119282800|          27.28265|\n",
      "|2010-01-08|210.299994|212.000006|209.06000500000002|211.98000499999998|  111902700|         27.464034|\n",
      "+----------+----------+----------+------------------+------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Date').sum().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(sales)|\n",
      "+----------+\n",
      "|     870.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.agg({'sales':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date| max(open)|\n",
      "+----------+----------+\n",
      "|2010-01-04|213.429998|\n",
      "|2010-01-05|214.599998|\n",
      "|2010-01-06|214.379993|\n",
      "|2010-01-07|    211.75|\n",
      "|2010-01-08|210.299994|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('date').agg({'open':'max'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|stddev_samp(sales)|\n",
      "+------------------+\n",
      "|250.08742410799007|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct,avg,stddev,format_number\n",
    "df2.select(stddev('sales') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|               std|\n",
      "+------------------+\n",
      "|250.08742410799007|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(stddev('sales') .alias('std')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   std|\n",
      "+------+\n",
      "|250.09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(stddev('sales') ).select(format_number('stddev_samp(sales)',2).alias('std')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   std|\n",
      "+------+\n",
      "|250.09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(format_number(stddev('sales'),2).alias('std')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "+-------+-------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc , expr\n",
    "df2.orderBy(\"sales\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|Company|Person|Sales|\n",
      "+-------+------+-----+\n",
      "|     FB|  Carl|870.0|\n",
      "|   APPL|  Mike|750.0|\n",
      "+-------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------+------+-----+\n",
      "|Company|Person|Sales|\n",
      "+-------+------+-----+\n",
      "|     FB|  Carl|870.0|\n",
      "|   APPL|  Mike|750.0|\n",
      "+-------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.orderBy(df2['sales'].desc()).show(2)\n",
    "df2.orderBy(col('sales').desc()).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
